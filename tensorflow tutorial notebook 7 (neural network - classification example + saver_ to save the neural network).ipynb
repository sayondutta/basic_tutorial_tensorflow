{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.1666\n",
      "0.8809\n",
      "0.8925\n",
      "0.8996\n",
      "0.9061\n",
      "0.9095\n",
      "0.9099\n",
      "0.9119\n",
      "0.9131\n",
      "0.9161\n",
      "0.9169\n",
      "0.9185\n",
      "0.919\n",
      "0.9178\n",
      "0.921\n",
      "0.9206\n",
      "0.9211\n",
      "0.9226\n",
      "0.9222\n",
      "0.9218\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#defining the structure of a layer\n",
    "\n",
    "def add_layer(inputs,in_size,out_size,activation_function=None):\n",
    "    #inputs from previous layer\n",
    "    #in_size: size(number of neurons) of previous layer\n",
    "    #out_size: size(number of neurons) of this layer\n",
    "    #activation_function: used in this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size,out_size]),name='W')\n",
    "    biases = tf.Variable(tf.zeros([1,out_size])+0.1,name='b')\n",
    "    logit = tf.matmul(inputs,Weights) + biases\n",
    "    if activation_function is None:\n",
    "        output = logit\n",
    "    else:\n",
    "        output = activation_function(logit,)\n",
    "    return output\n",
    "\n",
    "#calculating accuracy\n",
    "def compute_accuracy(xtest,ytest):\n",
    "    global predicted\n",
    "    ypred = sess.run(predicted,feed_dict={xs:xtest})\n",
    "    correct_pred = tf.equal(tf.arg_max(ypred,1),tf.arg_max(ytest,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "    result = sess.run(accuracy,feed_dict={xs:xtest,ys:ytest})\n",
    "    return result\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "#define placeholders for input to networks\n",
    "xs = tf.placeholder(tf.float32,[None,784])  #28x28=784\n",
    "ys = tf.placeholder(tf.float32,[None,10])   # 10 output classes\n",
    "\n",
    "#just adding one layer i.e. directly the output layer\n",
    "#adding one layer\n",
    "predicted = add_layer(xs,784,10,tf.nn.softmax)\n",
    "\n",
    "#y_hat_softmax = tf.nn.softmax(y_hat)  , yhat is logit\n",
    "#total_loss = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_hat_softmax), [1]))\n",
    "#or\n",
    "#total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true))\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(predicted),reduction_indices=[1]))\n",
    "training = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#important step\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "\n",
    "for i in range(20000):\n",
    "    batch_xs,batch_ys = mnist.train.next_batch(1000)\n",
    "    sess.run(training,feed_dict={xs:batch_xs,ys:batch_ys})\n",
    "    if i%100==0:\n",
    "        print compute_accuracy(mnist.test.images,mnist.test.labels)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saver : how to save your neural network\n",
    "#save to ckpt file type\n",
    "#remember the dtype, shape and name while restoring\n",
    "\n",
    "#next cell : saving weights and biases in ckpt file\n",
    "#next to next cell : restoring the weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "saved to path : my_net/nnet_classification.ckpt\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#defining the structure of a layer\n",
    "\n",
    "def add_layer(inputs,in_size,out_size,activation_function=None):\n",
    "    #inputs from previous layer\n",
    "    #in_size: size(number of neurons) of previous layer\n",
    "    #out_size: size(number of neurons) of this layer\n",
    "    #activation_function: used in this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size,out_size]),dtype=tf.float32,name='W')\n",
    "    biases = tf.Variable(tf.zeros([1,out_size])+0.1,dtype=tf.float32,name='b')\n",
    "    logit = tf.matmul(inputs,Weights) + biases\n",
    "    if activation_function is None:\n",
    "        output = logit\n",
    "    else:\n",
    "        output = activation_function(logit,)\n",
    "    return output\n",
    "\n",
    "#calculating accuracy\n",
    "def compute_accuracy(xtest,ytest):\n",
    "    global predicted\n",
    "    ypred = sess.run(predicted,feed_dict={xs:xtest})\n",
    "    correct_pred = tf.equal(tf.arg_max(ypred,1),tf.arg_max(ytest,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "    result = sess.run(accuracy,feed_dict={xs:xtest,ys:ytest})\n",
    "    return result\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "#define placeholders for input to networks\n",
    "xs = tf.placeholder(tf.float32,[None,784])  #28x28=784\n",
    "ys = tf.placeholder(tf.float32,[None,10])   # 10 output classes\n",
    "\n",
    "#just adding one layer i.e. directly the output layer\n",
    "#adding one layer\n",
    "predicted = add_layer(xs,784,10,tf.nn.softmax)\n",
    "\n",
    "#y_hat_softmax = tf.nn.softmax(y_hat)  , yhat is logit\n",
    "#total_loss = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_hat_softmax), [1]))\n",
    "#or\n",
    "#total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true))\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(predicted),reduction_indices=[1]))\n",
    "training = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "saver = tf.train.Saver() \n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#important step\n",
    "sess.run(tf.initialize_all_variables())\n",
    "savepath = saver.save(sess,'my_net/nnet_classification.ckpt')\n",
    "print \"saved to path : \"+savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': array([[ 0.44681871, -0.49384427, -0.10740629, ..., -1.49798536,\n",
      "         1.73851669,  0.15961084],\n",
      "       [-0.41313803, -1.08040404,  1.60866189, ...,  0.84048581,\n",
      "         1.36114597, -0.14927863],\n",
      "       [ 0.01632335, -0.92767048, -0.12213503, ..., -1.01318765,\n",
      "        -0.2912721 ,  0.45863724],\n",
      "       ..., \n",
      "       [-0.81792092, -0.62878609,  0.23398052, ...,  0.74413615,\n",
      "        -1.64972281, -0.53769708],\n",
      "       [-0.02011517,  0.45541522,  0.48796853, ..., -1.80807149,\n",
      "        -0.50324911,  1.18697643],\n",
      "       [ 0.45937699, -0.67307395, -0.24819164, ..., -0.95845032,\n",
      "        -1.49511802,  0.31245279]], dtype=float32), 'biases': array([[ 0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1,  0.1]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "#restore will need to redefine those weights\n",
    "#no need to run init\n",
    "\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def restore_layer_variable(in_size,out_size):\n",
    "    #inputs from previous layer\n",
    "    #in_size: size(number of neurons) of previous layer\n",
    "    #out_size: size(number of neurons) of this layer\n",
    "    #activation_function: used in this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size,out_size]),dtype=tf.float32,name='W')\n",
    "    biases = tf.Variable(tf.zeros([1,out_size])+0.1,dtype=tf.float32,name='b')\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess,'my_net/nnet_classification.ckpt')\n",
    "    return {'weights':sess.run(Weights),'biases':sess.run(biases)}\n",
    "    \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    l1 = restore_layer_variable(784,10)\n",
    "    print l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(20000):\n",
    "    batch_xs,batch_ys = mnist.train.next_batch(1000)\n",
    "    sess.run(training,feed_dict={xs:batch_xs,ys:batch_ys})\n",
    "    if i%100==0:\n",
    "        print compute_accuracy(mnist.test.images,mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abc=mnist.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcd,cde=abc.next_batch(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cde.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=tf.arg_max(cde,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 0, 8, 5, 2, 8, 7, 8, 6, 7, 1, 8, 5, 9, 2, 3, 6, 9, 4, 9, 1, 3,\n",
       "       8, 5, 7, 6, 5, 7, 5, 1, 1, 4, 8, 8, 9, 4, 1, 0, 3, 2, 6, 9, 3, 8, 3,\n",
       "       4, 2, 6, 2, 7, 6, 4, 6, 1, 5, 4, 5, 1, 3, 4, 3, 6, 8, 9, 1, 7, 6, 1,\n",
       "       5, 1, 6, 6, 8, 6, 1, 3, 9, 6, 7, 8, 6, 8, 8, 3, 3, 1, 7, 9, 9, 7, 0,\n",
       "       3, 0, 3, 3, 4, 7, 4, 9, 7, 3, 6, 0, 8, 2, 8, 0, 4, 1, 5, 0, 3, 1, 0,\n",
       "       0, 7, 1, 8, 0, 8, 4, 8, 7, 2, 9, 2, 2, 2, 0, 0, 6, 3, 2, 9, 6, 5, 2,\n",
       "       6, 2, 1, 9, 2, 9, 5, 0, 5, 1, 0, 2, 7, 3, 4, 4, 1, 5, 4, 6, 3, 8, 5,\n",
       "       9, 3, 0, 5, 1, 7, 3, 9, 4, 6, 5, 4, 6, 4, 7, 0, 8, 1, 9, 5, 0, 1, 1,\n",
       "       0, 2, 7, 3, 7, 4, 6, 5, 6, 6, 9, 7, 7, 8, 1, 9, 0, 1, 1, 8, 0, 6, 3,\n",
       "       7, 0, 1, 3, 3, 5, 7, 4, 7, 4, 9, 1, 3, 6, 6, 7, 0, 4, 2, 6, 6, 8, 4,\n",
       "       0, 8, 6, 4, 9, 5, 1, 0, 0, 3, 7, 9, 6, 2, 8, 1, 8, 1, 1, 5, 3, 9, 7,\n",
       "       4, 3, 2, 7, 0, 0, 4, 8, 4, 3, 0, 2, 9, 3, 6, 0, 9, 7, 2, 5, 2, 8, 1,\n",
       "       5, 7, 4, 9, 2, 5, 5, 1, 3, 1, 5, 9, 8, 6, 9, 0, 8, 1, 4, 8, 6, 4, 4,\n",
       "       6, 6, 8, 0, 8, 4, 2, 8, 6, 8, 3, 4, 2, 4, 9, 8, 2, 8, 4, 7, 0, 9, 9,\n",
       "       1, 0, 7, 3, 3, 3, 6, 5, 5, 8, 0, 4, 1, 7, 5, 6, 9, 2, 5, 2, 9, 7, 3,\n",
       "       7, 2, 0, 5, 5, 9, 1, 5, 5, 6, 3, 3, 0, 3, 1, 2, 2, 7, 3, 1, 4, 7, 5,\n",
       "       5, 6, 1, 7, 9, 8, 6, 0, 6, 1, 7, 4, 1, 7, 7, 0, 5, 1, 9, 4, 5, 7, 4,\n",
       "       8, 3, 9, 3, 6, 8, 8, 3, 2, 1, 4, 7, 6, 3, 8, 3, 6, 7, 6, 2, 7, 3, 1,\n",
       "       7, 7, 8, 0, 9, 2, 3, 2, 9, 0, 8, 1, 1, 6, 0, 5, 6, 1, 7, 2, 9, 0, 5,\n",
       "       2, 8, 3, 8, 4, 8, 8, 2, 3, 1, 7, 2, 4, 9, 1, 8, 7, 6, 4, 7, 8, 0, 3,\n",
       "       0, 9, 8, 6, 9, 7, 3, 0, 0, 9, 0, 6, 0, 0, 2, 6, 8, 1, 5, 0, 5, 5, 6,\n",
       "       5, 5, 1, 7, 0, 5, 1, 4, 0, 2, 9, 8, 4, 4, 5, 1, 9])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Session().run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  5.,  0.,  8.,  5.,  2.,  8.,  7.,  8.,  6.,  7.,  1.,  8.,\n",
       "        5.,  9.,  2.,  3.,  6.,  9.,  4.,  9.,  1.,  3.,  8.,  5.,  7.,\n",
       "        6.,  5.,  7.,  5.,  1.,  1.,  4.,  8.,  8.,  9.,  4.,  1.,  0.,\n",
       "        3.,  2.,  6.,  9.,  3.,  8.,  3.,  4.,  2.,  6.,  2.,  7.,  6.,\n",
       "        4.,  6.,  1.,  5.,  4.,  5.,  1.,  3.,  4.,  3.,  6.,  8.,  9.,\n",
       "        1.,  7.,  6.,  1.,  5.,  1.,  6.,  6.,  8.,  6.,  1.,  3.,  9.,\n",
       "        6.,  7.,  8.,  6.,  8.,  8.,  3.,  3.,  1.,  7.,  9.,  9.,  7.,\n",
       "        0.,  3.,  0.,  3.,  3.,  4.,  7.,  4.,  9.,  7.,  3.,  6.,  0.,\n",
       "        8.,  2.,  8.,  0.,  4.,  1.,  5.,  0.,  3.,  1.,  0.,  0.,  7.,\n",
       "        1.,  8.,  0.,  8.,  4.,  8.,  7.,  2.,  9.,  2.,  2.,  2.,  0.,\n",
       "        0.,  6.,  3.,  2.,  9.,  6.,  5.,  2.,  6.,  2.,  1.,  9.,  2.,\n",
       "        9.,  5.,  0.,  5.,  1.,  0.,  2.,  7.,  3.,  4.,  4.,  1.,  5.,\n",
       "        4.,  6.,  3.,  8.,  5.,  9.,  3.,  0.,  5.,  1.,  7.,  3.,  9.,\n",
       "        4.,  6.,  5.,  4.,  6.,  4.,  7.,  0.,  8.,  1.,  9.,  5.,  0.,\n",
       "        1.,  1.,  0.,  2.,  7.,  3.,  7.,  4.,  6.,  5.,  6.,  6.,  9.,\n",
       "        7.,  7.,  8.,  1.,  9.,  0.,  1.,  1.,  8.,  0.,  6.,  3.,  7.,\n",
       "        0.,  1.,  3.,  3.,  5.,  7.,  4.,  7.,  4.,  9.,  1.,  3.,  6.,\n",
       "        6.,  7.,  0.,  4.,  2.,  6.,  6.,  8.,  4.,  0.,  8.,  6.,  4.,\n",
       "        9.,  5.,  1.,  0.,  0.,  3.,  7.,  9.,  6.,  2.,  8.,  1.,  8.,\n",
       "        1.,  1.,  5.,  3.,  9.,  7.,  4.,  3.,  2.,  7.,  0.,  0.,  4.,\n",
       "        8.,  4.,  3.,  0.,  2.,  9.,  3.,  6.,  0.,  9.,  7.,  2.,  5.,\n",
       "        2.,  8.,  1.,  5.,  7.,  4.,  9.,  2.,  5.,  5.,  1.,  3.,  1.,\n",
       "        5.,  9.,  8.,  6.,  9.,  0.,  8.,  1.,  4.,  8.,  6.,  4.,  4.,\n",
       "        6.,  6.,  8.,  0.,  8.,  4.,  2.,  8.,  6.,  8.,  3.,  4.,  2.,\n",
       "        4.,  9.,  8.,  2.,  8.,  4.,  7.,  0.,  9.,  9.,  1.,  0.,  7.,\n",
       "        3.,  3.,  3.,  6.,  5.,  5.,  8.,  0.,  4.,  1.,  7.,  5.,  6.,\n",
       "        9.,  2.,  5.,  2.,  9.,  7.,  3.,  7.,  2.,  0.,  5.,  5.,  9.,\n",
       "        1.,  5.,  5.,  6.,  3.,  3.,  0.,  3.,  1.,  2.,  2.,  7.,  3.,\n",
       "        1.,  4.,  7.,  5.,  5.,  6.,  1.,  7.,  9.,  8.,  6.,  0.,  6.,\n",
       "        1.,  7.,  4.,  1.,  7.,  7.,  0.,  5.,  1.,  9.,  4.,  5.,  7.,\n",
       "        4.,  8.,  3.,  9.,  3.,  6.,  8.,  8.,  3.,  2.,  1.,  4.,  7.,\n",
       "        6.,  3.,  8.,  3.,  6.,  7.,  6.,  2.,  7.,  3.,  1.,  7.,  7.,\n",
       "        8.,  0.,  9.,  2.,  3.,  2.,  9.,  0.,  8.,  1.,  1.,  6.,  0.,\n",
       "        5.,  6.,  1.,  7.,  2.,  9.,  0.,  5.,  2.,  8.,  3.,  8.,  4.,\n",
       "        8.,  8.,  2.,  3.,  1.,  7.,  2.,  4.,  9.,  1.,  8.,  7.,  6.,\n",
       "        4.,  7.,  8.,  0.,  3.,  0.,  9.,  8.,  6.,  9.,  7.,  3.,  0.,\n",
       "        0.,  9.,  0.,  6.,  0.,  0.,  2.,  6.,  8.,  1.,  5.,  0.,  5.,\n",
       "        5.,  6.,  5.,  5.,  1.,  7.,  0.,  5.,  1.,  4.,  0.,  2.,  9.,\n",
       "        8.,  4.,  4.,  5.,  1.,  9.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Session().run(tf.cast(a,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
